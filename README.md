# Implementa√ß√£o do Mecanismo de Self-Attention
## **Descri√ß√£o**
Este projeto implementa o mecanismo de Scaled Dot-Product Attention, conforme descrito no paper [*Attention Is All You Need* (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762).


A implementa√ß√£o foi feita utilizando apenas NumPy, sem bibliotecas de alto n√≠vel de Deep Learning, conforme exigido no laborat√≥rio.

A f√≥rmula implementada √©:
$$
\text{Attention}(Q, K, V) =
\text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
$$

## **üß† Funcionamento Matem√°tico**
O mecanismo executa as seguintes etapas:

### **Produto Escalar**

$$
S = QK^T
$$


Mede a similaridade entre queries e keys.

### **Fator de Escala**

$$
\hat{S} = \frac{S}{\sqrt{d_k}}
$$



A divis√£o por ‚àödk evita que os valores cres√ßam excessivamente, o que poderia saturar o softmax e prejudicar o treinamento.

### **Softmax**

Cada linha √© normalizada para formar uma distribui√ß√£o de probabilidade.
$$
A_{ij} =
\frac{e^{\hat{S}_{ij}}}
{\sum_{j=1}^{n} e^{\hat{S}_{ij}}}
$$


### **Combina√ß√£o Ponderada**

$$
\text{Output} = A V
$$

Gera os embeddings contextuais finais.

## **‚öôÔ∏è Requisitos**
Criar ambiente virtual e instalar depend√™ncias:
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install numpy matplotlib seaborn

```
## **‚ñ∂Ô∏è Como Executar**
```bash
python test_attention.py
```
O script executa:

- Um exemplo com frase tokenizada

- Visualiza√ß√£o em heatmap da matriz de aten√ß√£o

## **üîç Visualiza√ß√£o**
O projeto tamb√©m plota:

- Matriz de pesos de aten√ß√£o (n √ó n)

Isso permite interpretar como cada token distribui sua aten√ß√£o entre os demais.

## **üìé Estrutura do Projeto**
```bash
implementando-self-attention/
‚îÇ
‚îú‚îÄ‚îÄ img
‚îú‚îÄ‚îÄ attention.py
‚îú‚îÄ‚îÄ test_attention.py
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

## **üéØ Objetivo Acad√™mico**
Este projeto tem como finalidade compreender profundamente:

- Produto escalar entre vetores

- Normaliza√ß√£o por ‚àödk

- Softmax linha por linha

- Mistura contextual via multiplica√ß√£o por V


## **üß† Explicando o Exemplo**

Foi utilizada a frase:

> "Os pinguins n√£o tem joelho"

Inicialmente, foi realizada a tokeniza√ß√£o da frase, gerando os seguintes tokens:
```py
["Os", "pinguins", "n√£o", "tem", "joelho"]
```

Em seguida, foi simulado um embedding vetorial para cada palavra.

Em um cen√°rio real, esses embeddings seriam obtidos por modelos pr√©-treinados, como Word2Vec, GloVe ou embeddings aprendidos diretamente durante o treinamento de um Transformer. Esses modelos s√£o treinados com grandes volumes de dados e capturam rela√ß√µes sem√¢nticas reais.

Neste projeto, os valores das matrizes foram definidos de forma proposital para gerar uma estrutura l√≥gica coerente com a sem√¢ntica da frase.

## **üìä Matriz de Attention Weights**

Ap√≥s a aplica√ß√£o do mecanismo de self-attention, obteve-se a seguinte matriz de pesos:

```python
attention_weights = 
[[0.29187513 0.17703122 0.17703122 0.17703122 0.17703122]
 [0.14396436 0.2373571  0.14396436 0.2373571  0.2373571 ]
 [0.15879462 0.15879462 0.26180807 0.26180807 0.15879462]
 [0.11541419 0.19028583 0.19028583 0.3137283  0.19028583]
 [0.12475479 0.20568587 0.12475479 0.20568587 0.33911868]]
```

A visualiza√ß√£o gr√°fica pode ser observada em:
![correla√ß√£o self-attention weights](img/self-attention_weights.png)

Cada linha representa a distribui√ß√£o de aten√ß√£o de um token (Query) em rela√ß√£o aos demais tokens (Keys).

### **üîé Interpreta√ß√£o Linha por Linha**
#### **"Os"**

Distribui√ß√£o:
```py
[0.29, 0.18, 0.18, 0.18, 0.18]
```

- Forte autoaten√ß√£o.

- Distribui√ß√£o quase uniforme para os demais tokens.

- Comportamento neutro e estruturalmente esperado para artigo definido.

#### **"pinguins"**

Distribui√ß√£o:
``` py
[0.14, 0.24, 0.14, 0.24, 0.24]
```

- Aten√ß√£o relevante em si mesmo.

- Aten√ß√£o significativa em:

    - "tem"

    - "joelho"

Isso √© estruturalmente coerente, pois:

- "pinguins" √© o sujeito da frase.

- Est√° ligado ao verbo "tem".

- Est√° semanticamente relacionado ao objeto "joelho".

#### **"n√£o"**

Distribui√ß√£o:
```py
[0.16, 0.16, 0.26, 0.26, 0.16]
```

- Divide aten√ß√£o entre si mesmo e "tem".

- Linguisticamente coerente, pois "n√£o" modifica o verbo "tem".

- Isso demonstra que a similaridade vetorial capturou uma rela√ß√£o sint√°tica relevante.

#### **"tem"**

Distribui√ß√£o:
```py
[0.12, 0.19, 0.19, 0.31, 0.19]
```

- Forte autoaten√ß√£o.

- Aten√ß√£o distribu√≠da entre:

    - "pinguins"

    - "n√£o"

    - "joelho"

Isso representa o verbo conectando sujeito e objeto.

#### **"joelho"**

Distribui√ß√£o:
```py
[0.12, 0.21, 0.12, 0.21, 0.34]
```

- Forte autoaten√ß√£o.

- Aten√ß√£o relevante em:

    - "pinguins"

    - "tem"

Novamente coerente com a estrutura sint√°tica da frase.

### **üß† Observa√ß√£o Importante**

√â importante destacar que, neste experimento:

- N√£o houve treinamento.

- N√£o houve aprendizado de par√¢metros.

- N√£o foram utilizadas matrizes W_Q, W_K e W_V aprend√≠veis.

A estrutura observada √© resultado da geometria do espa√ßo vetorial definido manualmente.

Em modelos Transformer reais, o aprendizado ajusta esse espa√ßo vetorial por meio de backpropagation, permitindo que o mecanismo de aten√ß√£o capture rela√ß√µes lingu√≠sticas complexas.

### **Conclus√£o do Exemplo**

Este experimento demonstra que o mecanismo de self-attention:

1. Mede similaridade vetorial.

2. Converte similaridade em probabilidades.

3. Gera representa√ß√µes contextuais a partir de combina√ß√µes ponderadas.

Mesmo sem treinamento, j√° √© poss√≠vel observar padr√µes coerentes com a estrutura sint√°tica da frase.

## üîé Curiosidade: Organiza√ß√£o no Espa√ßo Vetorial

Para ilustrar o efeito do self-attention, projetei os embeddings iniciais e os embeddings contextuais finais em duas dimens√µes utilizando PCA.

![espa√ßo vetorial](img/transformacao_embeddings.png)

No gr√°fico, cada palavra possui:

- Um ponto inicial (embedding est√°tico).
- Um ponto final (embedding ap√≥s self-attention).
- Uma linha indicando o deslocamento no espa√ßo vetorial.

Essa visualiza√ß√£o mostra como o mecanismo de aten√ß√£o reorganiza geometricamente os vetores.

Ap√≥s a aplica√ß√£o do self-attention, observa-se que:

- Palavras estruturalmente relacionadas tendem a se aproximar.
- A representa√ß√£o vetorial torna-se mais contextual.
- O espa√ßo passa a refletir rela√ß√µes sint√°ticas da frase.

√â importante destacar que essa organiza√ß√£o n√£o representa sem√¢ntica aprendida, pois n√£o houve treinamento do modelo. 

Em modelos Transformer reais, esse deslocamento vetorial √© resultado do aprendizado das matrizes \( W_Q, W_K, W_V \), permitindo que rela√ß√µes lingu√≠sticas complexas sejam codificadas geometricamente no espa√ßo vetorial.


## **üìö Refer√™ncias**

- Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A.N., Kaiser, ≈Å., & Polosukhin, I. (2017). *Attention Is All You Need*.  
  üìÑ https://arxiv.org/abs/1706.03762

- Romero, Daniel. *Explica√ß√£o completa do modelo Transformer com base no paper: Attention Is All You Need*.  
  üé• https://www.youtube.com/watch?v=aCWm4eMQlQs

